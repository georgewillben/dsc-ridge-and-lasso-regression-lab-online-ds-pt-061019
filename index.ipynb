{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the code in this lab was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge of Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:\n",
    "* Use Lasso and ridge regression in Python\n",
    "* Compare Lasso and Ridge with standard regression\n",
    "* Find optimal values of alpha for Lasso and Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make a selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n",
    "\n",
    "Make sure to remove the SalesPrice column from the predictors (which you store in `X`).\n",
    "\n",
    "Store the target in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "\n",
    "#create X and y then train test split\n",
    "features = [col for col in df.columns if col != 'SalePrice']\n",
    "X = df.loc[:, features]\n",
    "y = df.loc[:, 'SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "\n",
    "# remove object type features\n",
    "cont_features = [col for col in X.columns if X[col].dtype in [np.float64, np.int64]]\n",
    "X_train_cont = X_train.loc[:, cont_features]\n",
    "X_test_cont = X_test.loc[:, cont_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095, 365)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_cont), len(X_test_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to perform a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R squared and the MSE for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2:  0.8069714678400265\n",
      "Testing r2:  0.8203264293698926\n",
      "Training MSE:  1212415985.7084064\n",
      "Testing MSE:  1146350639.8805728\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# impute data\n",
    "impute = Imputer(strategy='median')\n",
    "impute.fit(X_train_cont)\n",
    "X_train_imputed = impute.transform(X_train_cont)\n",
    "X_test_imputed = impute.transform(X_test_cont)\n",
    "\n",
    "# create model and print stats\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_imputed, y_train)\n",
    "\n",
    "print('Training r2: ', reg.score(X_train_imputed, y_train))\n",
    "print('Testing r2: ', reg.score(X_test_imputed, y_test))\n",
    "print('Training MSE: ', mean_squared_error(y_train, reg.predict(X_train_imputed)))\n",
    "print('Testing MSE: ', mean_squared_error(y_test, reg.predict(X_test_imputed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't normalized our data, let's create a new model that uses `StandardScalar` to scale our predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train_imputed)\n",
    "X_train_imputed_scaled = ss.transform(X_train_imputed)\n",
    "X_test_imputed_scaled = ss.transform(X_test_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2:  0.8070159754195584\n",
      "Testing r2:  0.8202405055692075\n",
      "Training MSE:  1212136432.7308965\n",
      "Testing MSE:  1146898849.6342442\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_imputed_scaled, y_train)\n",
    "\n",
    "print('Training r2: ', reg.score(X_train_imputed_scaled, y_train))\n",
    "print('Testing r2: ', reg.score(X_test_imputed_scaled, y_test))\n",
    "print('Training MSE: ', mean_squared_error(y_train, reg.predict(X_train_imputed_scaled)))\n",
    "print('Testing MSE: ', mean_squared_error(y_test, reg.predict(X_test_imputed_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model hasn't included categorical variables so far: let's use the \"object\" variables again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "\n",
    "\n",
    "# Create X_cat which contains only the categorical variables\n",
    "features_cat = [col for col in X.columns if X[col].dtype in [np.object]]\n",
    "X_train_cat = X_train.loc[:, features_cat]\n",
    "X_test_cat = X_test.loc[:, features_cat]\n",
    "\n",
    "#Fill missing values with a string indicating that that it is missing\n",
    "X_train_cat.fillna(value='missing', inplace=True)\n",
    "X_test_cat.fillna(value='missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# OneHotEncode Categorical variables\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit(X_train_cat)\n",
    "\n",
    "X_train_ohe = ohe.transform(X_train_cat)\n",
    "X_test_ohe = ohe.transform(X_test_cat)\n",
    "\n",
    "columns = ohe.get_feature_names(input_features=X_train_cat.columns)\n",
    "cat_train_df = pd.DataFrame(X_train_ohe.todense(), columns=columns)\n",
    "cat_test_df = pd.DataFrame(X_test_ohe.todense(), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "X_train_all = pd.concat([pd.DataFrame(X_train_imputed_scaled), cat_train_df], axis=1) \n",
    "X_test_all = pd.concat([pd.DataFrame(X_test_imputed_scaled), cat_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095, 1095)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_all), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2:  0.9360007807588508\n",
      "Testing r2:  -9.0338451960491e+18\n",
      "Training MSE:  401980347.7369863\n",
      "Testing MSE:  5.7637604600137055e+28\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train_all, y_train)\n",
    "\n",
    "print('Training r2: ', reg_all.score(X_train_all, y_train))\n",
    "print('Testing r2: ', reg_all.score(X_test_all, y_test))\n",
    "print('Training MSE: ', mean_squared_error(y_train, reg_all.predict(X_train_all)))\n",
    "print('Testing MSE: ', mean_squared_error(y_test, reg_all.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far off. Similarly, the scale of the Testing MSE is orders of magnitude higher than that of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2:  0.9359681086176651\n",
      "Testing r2:  0.888684112594205\n",
      "Training MSE:  402185562.0947691\n",
      "Testing MSE:  710215967.2621557\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train_all, y_train)\n",
    "\n",
    "print('Training r2: ', lasso.score(X_train_all, y_train))\n",
    "print('Testing r2: ', lasso.score(X_test_all, y_test))\n",
    "print('Training MSE: ', mean_squared_error(y_train, lasso.predict(X_train_all)))\n",
    "print('Testing MSE: ', mean_squared_error(y_test, lasso.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2:  0.9343826511712741\n",
      "Testing r2:  0.8966777526569274\n",
      "Training MSE:  412143851.32359594\n",
      "Testing MSE:  659215063.9643544\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso(alpha=10)\n",
    "lasso.fit(X_train_all, y_train)\n",
    "\n",
    "print('Training r2: ', lasso.score(X_train_all, y_train))\n",
    "print('Testing r2: ', lasso.score(X_test_all, y_test))\n",
    "print('Training MSE: ', mean_squared_error(y_train, lasso.predict(X_train_all)))\n",
    "print('Testing MSE: ', mean_squared_error(y_test, lasso.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2:  0.9231940244796031\n",
      "Testing r2:  0.884233048544421\n",
      "Training MSE:  482419834.3987995\n",
      "Testing MSE:  738614579.8334152\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "\n",
    "\n",
    "\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train_all, y_train)\n",
    "\n",
    "print('Training r2: ', ridge.score(X_train_all, y_train))\n",
    "print('Testing r2: ', ridge.score(X_test_all, y_test))\n",
    "print('Training MSE: ', mean_squared_error(y_train, ridge.predict(X_train_all)))\n",
    "print('Testing MSE: ', mean_squared_error(y_test, ridge.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2:  0.8990002650425939\n",
      "Testing r2:  0.8834542222982166\n",
      "Training MSE:  634381310.5991352\n",
      "Testing MSE:  743583635.452231\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "\n",
    "\n",
    "\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(X_train_all, y_train)\n",
    "\n",
    "print('Training r2: ', ridge.score(X_train_all, y_train))\n",
    "print('Testing r2: ', ridge.score(X_test_all, y_test))\n",
    "print('Training MSE: ', mean_squared_error(y_train, ridge.predict(X_train_all)))\n",
    "print('Testing MSE: ', mean_squared_error(y_test, ridge.predict(X_test_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics, what are your main conclusions?   \n",
    "\n",
    "Conclusions here: <br>\n",
    "Lasso and Ridge regression did much better than normal linear regression. Lasso with an alpha of 10 seemed to be the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the total length of the parameter space and draw conclusions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "# number of ridge params close to zero\n",
    "print(sum(abs(ridge.coef_) < 10 ** (-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "# number of lasso params close to zero\n",
    "print(sum(abs(lasso.coef_) < 10 ** (-10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26013513513513514"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "\n",
    "sum(abs(lasso.coef_) < 10 ** (-10)) / len(lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To bring all of our work together lets take a moment to put all of our preprocessing steps for categorical and continuous variables into one function. This function should take in our features as a dataframe `X` and target as a Series `y` and return a training and test dataframe with all of our preprocessed features along with training and test targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in this cell was copied from the solution at https://github.com/learn-co-curriculum/dsc-ridge-and-lasso-regression-lab/tree/solution\n",
    "\n",
    "\n",
    "def preprocess(X, y):\n",
    "    '''Takes in features and target and implements all preprocessing steps for categorical and continuous features returning \n",
    "    train and test dataframes with targets'''\n",
    "    \n",
    "    #train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    # remove \"object\"-type features and SalesPrice from `X`\n",
    "    cont_cols = [col for col in X.columns if X[col].dtype in [np.float64, np.int64]]\n",
    "    X_train_cont, X_test_cont = X_train.loc[:, cont_cols], X_test.loc[:, cont_cols]\n",
    "    \n",
    "    # Impute missing values with median using Imputer from sklearn.preprocessing\n",
    "    impute = Imputer(strategy='median')\n",
    "    impute.fit(X_train_cont)\n",
    "    X_train_imputed = impute.transform(X_train_cont)\n",
    "    X_test_imputed = impute.transform(X_test_cont)\n",
    "\n",
    "    # Scale the train and test data\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train_imputed)\n",
    "    X_train_scaled = ss.transform(X_train_imputed)\n",
    "    X_test_scaled = ss.transform(X_test_imputed)\n",
    "\n",
    "    # Create X_cat which contains only the categorical variables\n",
    "    cat_cols = [col for col in X.columns if X[col].dtype in [np.object]]\n",
    "    X_train_cat = X_train.loc[:, cat_cols]\n",
    "    X_test_cat = X_test.loc[:, cat_cols]\n",
    "\n",
    "    \n",
    "    #Fill nans with a value indicating that that it is missing\n",
    "    X_train_cat.fillna(value='missing', inplace=True)\n",
    "    X_test_cat.fillna(value='missing', inplace=True)\n",
    "\n",
    "    # OneHotEncode Categorical variables\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe.fit(X_train_cat)\n",
    "    X_train_ohe = ohe.transform(X_train_cat)\n",
    "    X_test_ohe = ohe.transform(X_test_cat)\n",
    "    \n",
    "    columns = ohe.get_feature_names(input_features=X_train_cat.columns)\n",
    "    cat_train_df = pd.DataFrame(X_train_ohe.todense(), columns=columns)\n",
    "    cat_test_df = pd.DataFrame(X_test_ohe.todense(), columns=columns)\n",
    "    \n",
    "    # combine categorical and continuous features into the final dataframe\n",
    "    X_train_all = pd.concat([pd.DataFrame(X_train_scaled), cat_train_df], axis=1)\n",
    "    X_test_all = pd.concat([pd.DataFrame(X_test_scaled), cat_test_df], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train_all, X_test_all, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the Training and Test Error to Find Optimal Alpha Values\n",
    "\n",
    "Earlier we tested several values of alpha to see how it effected our MSE and the value of our coefficients. We could continue to guess values of alpha for our Ridge or Lasso regression one at a time to see which values minimize our loss, or we can test a range of values and pick the alpha which minimizes our MSE. Here is an example of how we would "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_test_all, y_train, y_test = preprocess(X, y)\n",
    "\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "alphas = []\n",
    "\n",
    "for alpha in np.linspace(0, 200, num=50):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_all, y_train)\n",
    "    \n",
    "    train_preds = lasso.predict(X_train_all)\n",
    "    train_mse.append(mean_squared_error(y_train, train_preds))\n",
    "    \n",
    "    test_preds = lasso.predict(X_test_all)\n",
    "    test_mse.append(mean_squared_error(y_test, test_preds))\n",
    "    \n",
    "    alphas.append(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value: 65\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alphas, train_mse, label='Train')\n",
    "ax.plot(alphas, test_mse, label='Test')\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('MSE')\n",
    "\n",
    "#np.argmin() returns the index of the minimum value in a list\n",
    "optimal_alpha = alphas[np.argmin(test_mse)]\n",
    "\n",
    "# add a vertical line where the testing MSE is minimized\n",
    "ax.axvline(optimal_alpha, color='black', linestyle='--')\n",
    "ax.legend();\n",
    "\n",
    "print(f'Optimal Alpha Value: {int(optimal_alpha)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at this graph of our training and testing MSE against alpha. Try to explain to yourself why the shapes of the training and test curves are this way. Make sure to think about what alpha represents and how it relates to overfitting vs underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up\n",
    "If you would like more practice doing this kind of analysis try to find the optimal value of alpha for a Ridge regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
